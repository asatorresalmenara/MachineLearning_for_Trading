{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQWfP-VMvX7c"
   },
   "source": [
    "# Clase que implementa un Algoritmo evolutivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada individuo se forma por un cromosoma formado por los siguientes genes:\n",
    "\n",
    "**Hiperparámetros estructurales**:\n",
    "\n",
    "- *loopback_window*: \n",
    "    rango:  0,7 \n",
    "    bits:   3\n",
    "    coding: 2^i\n",
    "    values: 0=1, 1=2, 2=4, 3=8, 4=16, 5=32, 6=64, 7=128\n",
    "- *forward_window*:\n",
    "    rango:  0,7\n",
    "    bits:   3\n",
    "    coding: 1+i\n",
    "    values: 0=1, 1=2, 2=3, 3=4, 4=5, 5=6, 6=7, 7=8\n",
    "- *num_lstm_layers*:\n",
    "    rango:  0,3\n",
    "    bits:   2\n",
    "    coding: 1+i\n",
    "    values: 0=1, 1=2, 2=3, 3=4\n",
    "- *num_dense_layers*: \n",
    "    rango:  0,1\n",
    "    bits:   1\n",
    "    coding: 2+i\n",
    "    values: 0=1, 1=2\n",
    "- *num_cells_per_layer*:\n",
    "    rango:  (0,3)\n",
    "    bits:   4\n",
    "    coding: default: 32, bit0=64 bit1=128 bit2=256 bit3=512 \n",
    "    values: 0=32, 1=64, 2=128, 3=192, ..., 15=960=512+256+128+64\n",
    "\n",
    "**Hiperparámetros de entrenamiento**:\n",
    "\n",
    "- *batch_size*: \n",
    "    rango:  (0,3)\n",
    "    bits:   4\n",
    "    coding: default: 1, bit0=8 bit1=16 bit2=32 bit3=64 \n",
    "    values: 0=1, 1=8, 2=16, 3=24, ..., 15=120=64+32+16+8\n",
    "- *suffling_enable*: rango (0,1), se codifica con 1 bits: 0=>(False), 1=>(True)\n",
    "    rango:  (0,1)\n",
    "    bits:   1\n",
    "    coding: (i) \n",
    "    values: 0=False, 1=True\n",
    "\n",
    "En resumen, cada individuo consta de 3+3+2+1+4+4+1 = 18 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################\n",
    "# Chequeo si está operativo el entorno de Google Colaboratory\n",
    "import sys\n",
    "ENABLE_GOOGLE_COLAB = 'google.colab' in sys.modules\n",
    "ENABLE_GOOGLE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo módulos necesarios para trabajar en google colab\n",
    "if ENABLE_GOOGLE_COLAB:\n",
    "    !pip install deap\n",
    "    !pip install bitstring\n",
    "    !pip install PyDrive\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    import talib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_GOOGLE_COLAB:\n",
    "    from google.colab import files\n",
    "    src = list(files.upload().values())[0]\n",
    "    open('PredictiveNet.py','wb').write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_GOOGLE_COLAB:\n",
    "    src = list(files.upload().values())[0]\n",
    "    open('EURUSD_H1.csv','wb').write(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PredictiveNet import PredictiveNet\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def predictive_net_decoder(chromosome):\n",
    "  \"\"\"\n",
    "  Decodifica un chromosoma en una solución tipo 'ind = list(features)'. En este caso contamos con 7 features:\n",
    "  lbw : loopback-window, 2-bits\n",
    "  fww : forward-window, 1-bits\n",
    "  nll : num-lstm-layers, 1-bits\n",
    "  ndl : num-dense-layers, 1-bit\n",
    "  nlc : num-layer-cells, 2-bits\n",
    "  bs  : batch-size, 2-bits\n",
    "  sf  : suffle-flag, 1-bit   \n",
    "\n",
    "  Returns:\n",
    "    Individuo, como una lista de features ind = [lbw,fww,nll,ndl,nlc,bs,sf], que será utilizado para realizar la evaluación\n",
    "  \"\"\"        \n",
    "  chromo =[BitArray(chromosome[0:2]).uint, BitArray(chromosome[2:3]).uint, BitArray(chromosome[3:4]).uint,\n",
    "           BitArray(chromosome[4:5]).uint, BitArray(chromosome[5:7]).uint, BitArray(chromosome[7:9]).uint,\n",
    "           BitArray(chromosome[9:10]).uint]\n",
    "  ind = []\n",
    "  # lbw\n",
    "  lbw = [8, 12, 24, 48]\n",
    "  ind.append(lbw[chromo[0]])\n",
    "  # fww\n",
    "  fww = [1,2]\n",
    "  ind.append(fww[chromo[1]])\n",
    "  # nll\n",
    "  nll = [1,2]\n",
    "  ind.append(nll[chromo[2]])\n",
    "  # ndl\n",
    "  ndl = [1,2]\n",
    "  ind.append(ndl[chromo[3]])\n",
    "  # nlc\n",
    "  nlc = [64, 128, 256, 512]\n",
    "  ind.append(nlc[chromo[4]])  \n",
    "  # bs\n",
    "  bs = [1, 16, 32, 64]\n",
    "  ind.append(bs[chromo[5]])  \n",
    "  # sf\n",
    "  sf = [False, True]\n",
    "  ind.append(sf[chromo[6]]) \n",
    "  return ind     \n",
    "\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def predictive_net_evaluator(ind):\n",
    "  \"\"\"\n",
    "  Evalúa un individuo, devolviendo su fitness (0,1).\n",
    "  Args:\n",
    "    ind : Individual\n",
    "\n",
    "  Returns:\n",
    "    fitness del individuo en el rango 0,1\n",
    "  \"\"\"       \n",
    "  # límite del val_acc para descartar a un individuo\n",
    "  DISCARD_ACC_THRESHOLD = 0.1\n",
    "  nn = PredictiveNet(ind.name,\n",
    "                     loopback_window=ind.genes[0], \n",
    "                     forward_window=ind.genes[1], \n",
    "                     num_lstm_layers=ind.genes[2], \n",
    "                     num_dense_layers=ind.genes[3],\n",
    "                     num_cells=ind.genes[4], \n",
    "                     batch_size=ind.genes[5],\n",
    "                     suffle_enable= ind.genes[6],\n",
    "                     tvt_csv_file='EURUSD_H1.csv')   \n",
    "  epochs = 2\n",
    "  for i in range(epochs):\n",
    "    history = nn.train_validate(1)\n",
    "    loss = history.history['val_loss'][0]\n",
    "    acc = history.history['val_acc'][0]\n",
    "    if acc < DISCARD_ACC_THRESHOLD:\n",
    "      print('Ind={}, loss={}, acc={}'.format(ind.name,loss,acc))   \n",
    "      print('---------------')\n",
    "      return acc      \n",
    "  loss,acc = nn.test_eval()\n",
    "  print('Ind={}, loss={}, acc={}'.format(ind.name,loss,acc))      \n",
    "  print('---------------')\n",
    "  return acc\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def simplistic_evaluator(ind):\n",
    "  \"\"\"\n",
    "  Evalúa un individuo, devolviendo su fitness (0,1).\n",
    "  Args:\n",
    "    ind : Individual\n",
    "\n",
    "  Returns:\n",
    "    fitness del individuo en el rango 0,1\n",
    "  \"\"\"       \n",
    "  acc = (ind.genes[2] + ind.genes[4])/1026\n",
    "  print('Ind={}, acc={}'.format(ind.name,acc))      \n",
    "  return acc\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def save_to_file(obj, filepath):\n",
    "  with open(filepath, 'wb') as f:\n",
    "    try:\n",
    "      pickle.dump(obj, f)\n",
    "    except MemoryError as error:\n",
    "      exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "      print('type:', exc_type, 'value:', exc_value)\n",
    "        \n",
    "        \n",
    "#-------------------------------------------------------------\n",
    "def load_from_file(filepath):\n",
    "  with open(filepath, 'rb') as f:\n",
    "    obj = pickle.load(f)        \n",
    "  return obj   \n",
    "\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "class Individual:\n",
    "  def __init__(self, chromosome, decoder):\n",
    "    \"\"\"\n",
    "      Crea un un individuo a partir de un cromosoma binario\n",
    "      Args:\n",
    "        chromosome: Cromosoma binario generado por deap.toolbox\n",
    "        decoder   : Callback de decodificación del cromosoma\n",
    "    \"\"\"\n",
    "    self.genes = decoder(chromosome)\n",
    "    self.name = str(self.genes)                 \n",
    "\n",
    "        \n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "class GA:\n",
    "  def __init__(self, popsize, genesize, chr_decoder, ind_evaluator):\n",
    "    \"\"\"\n",
    "      Crea el algoritmo genético\n",
    "      Args:\n",
    "        popsize       : Tamaño de la población\n",
    "        genesize      : Número de genes en el cromosoma\n",
    "        chr_decoder   : Callback para decodificar un cromosoma en un individuo evaluable\n",
    "        ind_evaluator : Callback para evaluar individuos\n",
    "    \"\"\"      \n",
    "    self.toolbox = None\n",
    "    self.popsize = popsize\n",
    "    self.genesize = genesize\n",
    "    self.chr_decoder = chr_decoder\n",
    "    self.ind_evaluator = ind_evaluator\n",
    "    self.restart()\n",
    "\n",
    "    # As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "    # In case, when you want to maximize accuracy for instance, use 1.0\n",
    "    print('Creando GA...')\n",
    "    creator.create('FitnessMax', base.Fitness, weights = (1.0,))\n",
    "    creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = self.genesize)\n",
    "    toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "    toolbox.register('mate', tools.cxOrdered)\n",
    "    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.05)\n",
    "    toolbox.register('select', tools.selRoulette)\n",
    "    toolbox.register('evaluate', self.evaluate_individual)\n",
    "    self.population = toolbox.population(n = self.popsize)\n",
    "    self.toolbox = toolbox        \n",
    "    self.summary()\n",
    "                                 \n",
    "  #-------------------------------------------------------------\n",
    "  def summary(self):\n",
    "    print('Individuals:')\n",
    "    for chromo in self.population:\n",
    "      ind = Individual(chromo, self.chr_decoder)\n",
    "      print(ind.genes)\n",
    "                                 \n",
    "  #-------------------------------------------------------------\n",
    "  def evaluate_individual(self, chromosome):\n",
    "    ind = Individual(chromosome, self.chr_decoder)\n",
    "    fitness = self.ind_evaluator(ind)\n",
    "    return [fitness]    \n",
    "                        \n",
    "  #-------------------------------------------------------------\n",
    "  def restart(self):\n",
    "    self.generations = 0\n",
    "    self.results = []\n",
    "    \n",
    "  #-------------------------------------------------------------\n",
    "  def execute(self, numgens, pcross, pmut):\n",
    "    print('Ejecutando GA de generación={} a generación={}'.format(self.generations, self.generations + numgens - 1))\n",
    "    self.stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    self.stats.register(\"avg\", np.mean)\n",
    "    self.stats.register(\"std\", np.std)\n",
    "    self.stats.register(\"min\", np.min)\n",
    "    self.stats.register(\"max\", np.max)    \n",
    "    self.hallOfFame = tools.HallOfFame(self.popsize/2)\n",
    "    self.results = []\n",
    "    for g in range(numgens):\n",
    "      print('-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-')            \n",
    "      pop,log = algorithms.eaSimple(self.population, self.toolbox, cxpb = pcross, mutpb = pmut, ngen = 1, stats = self.stats, halloffame=self.hallOfFame, verbose = False)\n",
    "      self.generations += 1\n",
    "      self.results.append({'gen': self.generations,'fitmax':log[1]['max'], 'fitavg': log[1]['avg'], 'fitstd': log[1]['std'], 'fitmin': log[1]['min'], 'best': self.hallOfFame[0]})\n",
    "      print(self.results[-1])\n",
    "      obj = {'pop': self.population, 'results': self.results}\n",
    "      filename = 'ga_'+str(self.generations)+'.pickle'\n",
    "      save_to_file(obj, filename)\n",
    "      if ENABLE_GOOGLE_COLAB:\n",
    "        files.download(filename)\n",
    "      \n",
    "    return self.results\n",
    "    \n",
    "        \n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando GA...\n",
      "Individuals:\n",
      "[8, 1, 1, 2, 512, 64, True]\n",
      "[24, 2, 2, 2, 256, 1, True]\n",
      "[24, 1, 1, 2, 64, 64, False]\n",
      "[12, 2, 2, 1, 128, 32, True]\n",
      "[12, 1, 1, 2, 128, 1, True]\n",
      "[48, 1, 2, 1, 256, 1, True]\n",
      "[24, 2, 2, 1, 256, 64, False]\n",
      "[8, 2, 2, 2, 512, 1, True]\n",
      "[24, 2, 1, 1, 128, 64, True]\n",
      "[12, 2, 1, 2, 128, 16, False]\n"
     ]
    }
   ],
   "source": [
    "popsize = 10\n",
    "genesize = 10\n",
    "ga = GA(popsize, genesize, predictive_net_decoder, predictive_net_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando GA de generación=0 a generación=4\n",
      "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "file \"[8, 1, 1, 2, 512, 64, True]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 87s - loss: 0.0061 - acc: 1.4102e-05 - val_loss: 0.1505 - val_acc: 0.0000e+00\n",
      "Ind=[8, 1, 1, 2, 512, 64, True], loss=0.1505276140047591, acc=0.0\n",
      "---------------\n",
      "file \"[24, 2, 2, 2, 256, 1, True]_fitlog.csv\" updated\n",
      "Train on 71056 samples, validate on 17764 samples\n",
      "Epoch 1/1\n",
      " - 1711s - loss: 2.5020e-04 - acc: 0.4942 - val_loss: 0.4564 - val_acc: 0.5203\n",
      "Train on 71056 samples, validate on 17764 samples\n",
      "Epoch 1/1\n",
      " - 1706s - loss: 1.2426e-04 - acc: 0.4949 - val_loss: 0.4562 - val_acc: 0.5203\n",
      "Ind=[24, 2, 2, 2, 256, 1, True], loss=0.051132689025389935, acc=0.5013958933717579\n",
      "---------------\n",
      "file \"[24, 1, 1, 2, 64, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.0045 - acc: 2.8204e-05 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
      "Ind=[24, 1, 1, 2, 64, 64, False], loss=0.04650474858780422, acc=0.0\n",
      "---------------\n",
      "file \"[12, 2, 2, 1, 128, 32, True]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0041 - acc: 0.5002 - val_loss: 0.1937 - val_acc: 0.5191\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0046 - acc: 0.5010 - val_loss: 0.0876 - val_acc: 0.5126\n",
      "Ind=[12, 2, 2, 1, 128, 32, True], loss=0.008695152686605524, acc=0.5026079136690648\n",
      "---------------\n",
      "file \"[12, 1, 1, 2, 128, 1, True]_fitlog.csv\" updated\n",
      "Train on 71064 samples, validate on 17766 samples\n",
      "Epoch 1/1\n",
      " - 343s - loss: 1.9771e-04 - acc: 1.4072e-05 - val_loss: 0.4585 - val_acc: 5.6287e-05\n",
      "Ind=[12, 1, 1, 2, 128, 1, True], loss=0.45847456020990074, acc=5.628729032984352e-05\n",
      "---------------\n",
      "file \"[48, 1, 2, 1, 256, 1, True]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 2602s - loss: 2.8998e-04 - acc: 2.8153e-05 - val_loss: 0.4518 - val_acc: 0.0000e+00\n",
      "Ind=[48, 1, 2, 1, 256, 1, True], loss=0.4517689659829371, acc=0.0\n",
      "---------------\n",
      "file \"[24, 2, 2, 1, 256, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 127s - loss: 0.0038 - acc: 0.4994 - val_loss: 0.0884 - val_acc: 0.4784\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 125s - loss: 0.0032 - acc: 0.4993 - val_loss: 0.0121 - val_acc: 0.5103\n",
      "Ind=[24, 2, 2, 1, 256, 64, False], loss=0.0009404600793262568, acc=0.5015633375022334\n",
      "---------------\n",
      "file \"[8, 2, 2, 2, 512, 1, True]_fitlog.csv\" updated\n",
      "Train on 71068 samples, validate on 17767 samples\n",
      "Epoch 1/1\n",
      " - 6850s - loss: 2.6415e-04 - acc: 0.4914 - val_loss: 0.4635 - val_acc: 0.5086\n",
      "Train on 71068 samples, validate on 17767 samples\n",
      "Epoch 1/1\n",
      " - 6938s - loss: 1.3540e-04 - acc: 0.4927 - val_loss: 0.4780 - val_acc: 0.5128\n",
      "Ind=[8, 2, 2, 2, 512, 1, True], loss=0.056566298615539, acc=0.5011932099599261\n",
      "---------------\n",
      "file \"[24, 2, 1, 1, 128, 64, True]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 17s - loss: 0.0027 - acc: 0.4984 - val_loss: 0.0070 - val_acc: 0.4909\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 16s - loss: 0.0010 - acc: 0.5004 - val_loss: 0.0041 - val_acc: 0.5156\n",
      "Ind=[24, 2, 1, 1, 128, 64, True], loss=0.0004770158967072417, acc=0.5027246739324638\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0020 - acc: 0.5004 - val_loss: 0.2359 - val_acc: 0.5099\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0021 - acc: 0.5005 - val_loss: 0.2196 - val_acc: 0.5123\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.02118731161455951, acc=0.502113309352518\n",
      "---------------\n",
      "file \"[24, 2, 2, 2, 256, 32, True]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 172s - loss: 0.0035 - acc: 0.4987 - val_loss: 0.3285 - val_acc: 0.4895\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 169s - loss: 0.0047 - acc: 0.5008 - val_loss: 0.2527 - val_acc: 0.5211\n",
      "Ind=[24, 2, 2, 2, 256, 32, True], loss=0.025058728411394688, acc=0.5014396256973187\n",
      "---------------\n",
      "file \"[24, 2, 2, 1, 256, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 194s - loss: 0.0023 - acc: 0.4997 - val_loss: 0.2895 - val_acc: 0.5178\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 193s - loss: 0.0027 - acc: 0.4991 - val_loss: 0.3736 - val_acc: 0.4921\n",
      "Ind=[24, 2, 2, 1, 256, 16, False], loss=0.06001873683936482, acc=0.5059384560014396\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 1, True]_fitlog.csv\" updated\n",
      "Train on 71064 samples, validate on 17766 samples\n",
      "Epoch 1/1\n",
      " - 357s - loss: 1.9869e-04 - acc: 0.4953 - val_loss: 0.4527 - val_acc: 0.5137\n",
      "Train on 71064 samples, validate on 17766 samples\n",
      "Epoch 1/1\n",
      " - 356s - loss: 9.8258e-05 - acc: 0.4988 - val_loss: 0.4581 - val_acc: 0.5138\n",
      "Ind=[12, 2, 1, 2, 128, 1, True], loss=0.052382520886704906, acc=0.5018910400720397\n",
      "---------------\n",
      "file \"[24, 2, 2, 2, 256, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 197s - loss: 0.0019 - acc: 0.5001 - val_loss: 0.3733 - val_acc: 0.4898\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 197s - loss: 0.0020 - acc: 0.4990 - val_loss: 0.3945 - val_acc: 0.4838\n",
      "Ind=[24, 2, 2, 2, 256, 16, False], loss=0.041083657670961886, acc=0.49964009357567035\n",
      "---------------\n",
      "{'gen': 1, 'fitmax': 0.5059384560014396, 'fitavg': 0.5021650464191237, 'fitstd': 0.0014799075954274811, 'fitmin': 0.49964009357567035, 'best': [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]}\n",
      "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0021 - acc: 0.5026 - val_loss: 0.1909 - val_acc: 0.5112\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0021 - acc: 0.4988 - val_loss: 0.1223 - val_acc: 0.5150\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.012999177684865701, acc=0.5014388489208633\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 25s - loss: 0.0019 - acc: 0.5030 - val_loss: 0.0932 - val_acc: 0.5117\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.0019 - acc: 0.5011 - val_loss: 0.0806 - val_acc: 0.5140\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0073987696958329185, acc=0.5013039568345323\n",
      "---------------\n",
      "file \"[8, 2, 2, 1, 512, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 810s - loss: 0.0059 - acc: 0.5007 - val_loss: 0.3515 - val_acc: 0.5069\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 814s - loss: 0.0032 - acc: 0.4987 - val_loss: 0.4031 - val_acc: 0.5168\n",
      "Ind=[8, 2, 2, 1, 512, 16, False], loss=0.040337251260804674, acc=0.5013486782952706\n",
      "---------------\n",
      "file \"[8, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 21s - loss: 0.0021 - acc: 0.4983 - val_loss: 0.2455 - val_acc: 0.5111\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 19s - loss: 0.0023 - acc: 0.5002 - val_loss: 0.2024 - val_acc: 0.4919\n",
      "Ind=[8, 2, 1, 2, 128, 16, False], loss=0.02043838444318549, acc=0.49806689444344543\n",
      "---------------\n",
      "file \"[48, 2, 2, 1, 256, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 237s - loss: 0.0046 - acc: 0.5014 - val_loss: 0.0994 - val_acc: 0.5092\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 238s - loss: 0.0028 - acc: 0.5010 - val_loss: 0.0395 - val_acc: 0.5162\n",
      "Ind=[48, 2, 2, 1, 256, 64, False], loss=0.0029721826899208933, acc=0.5017438740833482\n",
      "---------------\n",
      "file \"[24, 2, 2, 1, 256, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 198s - loss: 0.0054 - acc: 0.5027 - val_loss: 0.2498 - val_acc: 0.5177\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 197s - loss: 0.0132 - acc: 0.5018 - val_loss: 0.2837 - val_acc: 0.5177\n",
      "Ind=[24, 2, 2, 1, 256, 16, False], loss=0.017415459182478346, acc=0.5014396256973187\n",
      "---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file \"[24, 2, 2, 1, 256, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 126s - loss: 0.0016 - acc: 0.4993 - val_loss: 0.0151 - val_acc: 0.5021\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 126s - loss: 0.0018 - acc: 0.5002 - val_loss: 0.0279 - val_acc: 0.5143\n",
      "Ind=[24, 2, 2, 1, 256, 64, False], loss=0.001987830761396772, acc=0.5025460067893515\n",
      "---------------\n",
      "{'gen': 2, 'fitmax': 0.5025460067893515, 'fitavg': 0.5014227813121683, 'fitstd': 0.0011864801749060304, 'fitmin': 0.49806689444344543, 'best': [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]}\n",
      "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "file \"[8, 1, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 23s - loss: 0.0021 - acc: 2.8153e-05 - val_loss: 0.2568 - val_acc: 0.0000e+00\n",
      "Ind=[8, 1, 1, 2, 128, 16, False], loss=0.25679564515686815, acc=0.0\n",
      "---------------\n",
      "file \"[8, 1, 2, 1, 256, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 0.0041 - acc: 1.4102e-05 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Ind=[8, 1, 2, 1, 256, 64, False], loss=0.10969657949966274, acc=0.0\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0017 - acc: 0.5049 - val_loss: 0.0639 - val_acc: 0.5135\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0017 - acc: 0.5020 - val_loss: 0.0546 - val_acc: 0.5108\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.005921505154008175, acc=0.5011241007194245\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0015 - acc: 0.5024 - val_loss: 0.0490 - val_acc: 0.5110\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0015 - acc: 0.5001 - val_loss: 0.0451 - val_acc: 0.5139\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.00405243085071102, acc=0.5013039568345323\n",
      "---------------\n",
      "file \"[8, 2, 2, 1, 256, 64, False]_fitlog.csv\" updated\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 58s - loss: 0.0041 - acc: 0.5012 - val_loss: 0.1269 - val_acc: 0.4885\n",
      "Train on 70912 samples, validate on 17728 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 0.0078 - acc: 0.4989 - val_loss: 0.0675 - val_acc: 0.5156\n",
      "Ind=[8, 2, 2, 1, 256, 64, False], loss=0.005926217574124166, acc=0.5060703445813247\n",
      "---------------\n",
      "file \"[24, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.0020 - acc: 0.4972 - val_loss: 0.2446 - val_acc: 0.4859\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.0023 - acc: 0.5010 - val_loss: 0.1808 - val_acc: 0.4844\n",
      "Ind=[24, 2, 1, 2, 128, 16, False], loss=0.01649070439387879, acc=0.4995501169695879\n",
      "---------------\n",
      "{'gen': 3, 'fitmax': 0.5060703445813247, 'fitavg': 0.40117808811742145, 'fitstd': 0.20059836789934216, 'fitmin': 0.0, 'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]}\n",
      "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "file \"[8, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.0022 - acc: 0.4989 - val_loss: 0.1488 - val_acc: 0.5177\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 22s - loss: 0.0020 - acc: 0.4954 - val_loss: 0.1008 - val_acc: 0.5146\n",
      "Ind=[8, 2, 1, 2, 128, 16, False], loss=0.011293534631255691, acc=0.501303722352095\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0014 - acc: 0.5012 - val_loss: 0.0422 - val_acc: 0.5142\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.0014 - acc: 0.4991 - val_loss: 0.0363 - val_acc: 0.5140\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0022362013791739723, acc=0.5013039568345323\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0013 - acc: 0.5013 - val_loss: 0.0371 - val_acc: 0.5140\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0013 - acc: 0.5032 - val_loss: 0.0296 - val_acc: 0.5140\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0028770261916372035, acc=0.5013938848920864\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0012 - acc: 0.5031 - val_loss: 0.0342 - val_acc: 0.5140\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0012 - acc: 0.5027 - val_loss: 0.0300 - val_acc: 0.5154\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.002776678283909569, acc=0.5012589928057554\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0012 - acc: 0.5002 - val_loss: 0.0302 - val_acc: 0.5140\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0011 - acc: 0.4977 - val_loss: 0.0283 - val_acc: 0.5140\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0020831927486695393, acc=0.5013489208633094\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0011 - acc: 0.5011 - val_loss: 0.0286 - val_acc: 0.5137\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0012 - acc: 0.4993 - val_loss: 0.0304 - val_acc: 0.5137\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0019367546117560052, acc=0.5014388489208633\n",
      "---------------\n",
      "{'gen': 4, 'fitmax': 0.502113309352518, 'fitavg': 0.5011106228306332, 'fitstd': 0.0010405076796771624, 'fitmin': 0.49806689444344543, 'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]}\n",
      "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0011 - acc: 0.5020 - val_loss: 0.0286 - val_acc: 0.5139\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0012 - acc: 0.5018 - val_loss: 0.0291 - val_acc: 0.5139\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0015591986417378156, acc=0.5013938848920864\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0011 - acc: 0.5019 - val_loss: 0.0268 - val_acc: 0.5137\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0011 - acc: 0.4996 - val_loss: 0.0268 - val_acc: 0.5140\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0012028148562871369, acc=0.5013938848920864\n",
      "---------------\n",
      "file \"[8, 1, 1, 1, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0015 - acc: 2.8153e-05 - val_loss: 0.0999 - val_acc: 0.0000e+00\n",
      "Ind=[8, 1, 1, 1, 128, 16, False], loss=0.09986055653793104, acc=0.0\n",
      "---------------\n",
      "file \"[8, 1, 1, 1, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 28s - loss: 0.0015 - acc: 2.8153e-05 - val_loss: 0.0563 - val_acc: 0.0000e+00\n",
      "Ind=[8, 1, 1, 1, 128, 16, False], loss=0.05633981955257646, acc=0.0\n",
      "---------------\n",
      "file \"[12, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0011 - acc: 0.5011 - val_loss: 0.0310 - val_acc: 0.5138\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0011 - acc: 0.5018 - val_loss: 0.0280 - val_acc: 0.5139\n",
      "Ind=[12, 2, 1, 2, 128, 16, False], loss=0.0019080297811092059, acc=0.5012589928057554\n",
      "---------------\n",
      "file \"[8, 2, 1, 2, 128, 16, False]_fitlog.csv\" updated\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0019 - acc: 0.4966 - val_loss: 0.0851 - val_acc: 0.5167\n",
      "Train on 71040 samples, validate on 17760 samples\n",
      "Epoch 1/1\n",
      " - 27s - loss: 0.0020 - acc: 0.4990 - val_loss: 0.0712 - val_acc: 0.5169\n",
      "Ind=[8, 2, 1, 2, 128, 16, False], loss=0.008732718175026572, acc=0.5016184139543247\n",
      "---------------\n",
      "{'gen': 5, 'fitmax': 0.5016184139543247, 'fitavg': 0.400777859909519, 'fitstd': 0.2003913587194204, 'fitmin': 0.0, 'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "num_generations = 5\n",
    "pcross = 0.5\n",
    "pmut = 0.01\n",
    "results = ga.execute(num_generations, pcross, pmut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gen': 1,\n",
       "  'fitmax': 0.5059384560014396,\n",
       "  'fitavg': 0.5021650464191237,\n",
       "  'fitstd': 0.0014799075954274811,\n",
       "  'fitmin': 0.49964009357567035,\n",
       "  'best': [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]},\n",
       " {'gen': 2,\n",
       "  'fitmax': 0.5025460067893515,\n",
       "  'fitavg': 0.5014227813121683,\n",
       "  'fitstd': 0.0011864801749060304,\n",
       "  'fitmin': 0.49806689444344543,\n",
       "  'best': [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]},\n",
       " {'gen': 3,\n",
       "  'fitmax': 0.5060703445813247,\n",
       "  'fitavg': 0.40117808811742145,\n",
       "  'fitstd': 0.20059836789934216,\n",
       "  'fitmin': 0.0,\n",
       "  'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]},\n",
       " {'gen': 4,\n",
       "  'fitmax': 0.502113309352518,\n",
       "  'fitavg': 0.5011106228306332,\n",
       "  'fitstd': 0.0010405076796771624,\n",
       "  'fitmin': 0.49806689444344543,\n",
       "  'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]},\n",
       " {'gen': 5,\n",
       "  'fitmax': 0.5016184139543247,\n",
       "  'fitavg': 0.400777859909519,\n",
       "  'fitstd': 0.2003913587194204,\n",
       "  'fitmin': 0.0,\n",
       "  'best': [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinTech_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
